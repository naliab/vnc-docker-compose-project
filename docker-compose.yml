services:
  db:
    image: postgres:16.1-alpine3.19
    container_name: "db"
    environment:
      POSTGRES_DB: "spark"
      POSTGRES_USER: "spark_user"
      POSTGRES_PASSWORD: "spark_password"
    ports:
      - "5432:5432"
    volumes:
      - ./house_prices.csv:/house_prices.csv
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
  spark-master:
    image: spark:python3
    container_name: "spark-master"
    ports:
      - "9090:8080"
      - "7077:7077"
    environment:
      SPARK_MODE: "master"
      SPARK_LOCAL_IP: "spark-master"
      SPARK_MASTER_PORT: "7077"
      SPARK_MASTER_WEBUI_PORT: "8080"
    command: "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://spark-master:8080"]
      interval: 5s
      timeout: 3s
      retries: 5
  spark-worker-1:
    image: spark:python3
    container_name: "spark-worker-1"
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "9091:8080"
      - "7000:7000"
    environment:
      SPARK_MODE: "worker"
      SPARK_MASTER: "spark://spark-master:7077"
      SPARK_WORKER_WEBUI_PORT: "8080"
    command: "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"
  spark-worker-2:
    image: spark:python3
    container_name: "spark-worker-2"
    depends_on:
      spark-master:
        condition: service_healthy
    ports:
      - "9092:8080"
      - "7001:7000"
    environment:
      SPARK_MODE: "worker"
      SPARK_MASTER: "spark://spark-master:7077"
      SPARK_WORKER_WEBUI_PORT: "8080"
    command: "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077"
